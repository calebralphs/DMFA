{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import math\n",
    "import pprint\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-processing\n",
    "\n",
    "The purpose of this cell is to select all of the data from the master excel sheet that is difficult to handle and output this data to a new excel sheet to be further altered and added to. Once ran once, this cell is pretty much rendered useless because it would overwrite any additions you make on the target output excel sheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing master excel document and extracting relevant data\n",
    "data_raw = pd.read_excel('Input_Final_LIBSRATE.xlsx', 'Input', header = 4)\n",
    "auto_data = data_raw.drop(list(range(0, 9)))\n",
    "auto_data.drop(list(auto_data.columns)[82:], axis = 1)\n",
    "desired_columns = ['Parameters:', 'Population (low)', 'CpC (baseline)', 'S1.2', 'S1.3', 'S1.4', 'S1.5', 'S1.6', 'S1.7', 'S1.8', 'S1.9', 'S1.10', 'S1.11', 'S1.12', 'S1.13', 'S1.14']\n",
    "auto_data = pd.concat([auto_data[col] for col in auto_data.columns if col in desired_columns], axis = 1)\n",
    "auto_data.columns = ['Year', 'Population', 'CpC', 'Closures', 'Bumpers', 'Engine Blocks', 'Heat Exchangers', 'Cylinder Heads', 'Suspension', 'Steering', 'Wheels', 'Transmission/Driveline', 'Brake Componenets', 'Other Engine', 'Body', 'Other Components']\n",
    "auto_data.set_index('Year')\n",
    "writer = pd.ExcelWriter('LIBS Rate ipynb Output Data.xlsx')\n",
    "auto_data.to_excel(writer, 'Auto Data', index = False, index_label = 'Year')\n",
    "\n",
    "# Importing alloy information\n",
    "alloys_raw = sio.loadmat('alloys_info.mat')\n",
    "\n",
    "# Parsing .MAT raw data into hierarchical array representation\n",
    "# [alloy, type, [nominal[], min[], max[]]]\n",
    "alloys_info = []\n",
    "for alloy in alloys_raw['alloys_info'][0]:\n",
    "    alloys_info.append([alloy[0][0][0][0], alloy[3][0], 'Nominal', *list(alloy[1][0])])\n",
    "    alloys_info.append([alloy[0][0][0][0], alloy[3][0], 'Minimum', *list(alloy[2][1])])\n",
    "    alloys_info.append([alloy[0][0][0][0], alloy[3][0], 'Maximum', *list(alloy[2][0])])\n",
    "alloys_info = pd.DataFrame(alloys_info)\n",
    "alloys_info.columns = ['Alloy', 'Type', 'Level', 'Si', 'Fe', 'Cu', 'Mn', 'Mg', 'Cr', 'Ni', 'Zn', 'Ti']\n",
    "alloys_info_table = pd.DataFrame(alloys_info)\n",
    "#alloys_info_table = pd.pivot_table(alloys_info, \n",
    "#                       index = ['Alloy', 'Type', 'Level'],\n",
    "#                       values = ['Level', 'Si', 'Fe', 'Cu', 'Mn', 'Mg', 'Cr', 'Ni', 'Zn', 'Ti'])\n",
    "alloys_info_table.to_excel(writer, 'Alloy Data', index = False)\n",
    "alloys_info.set_index('Alloy', drop = True)#['Alloy', 'Type', 'Level'], drop = True)\n",
    "\n",
    "writer.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Scenario Conditions, Parameters, and Wrangle Data\n",
    "\n",
    "TODO:\n",
    "- Create function to input parameters for scenarios\n",
    "- Add parameters for starting year, and whatever criterion will be dynamic between this model and the regional ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "##### SCENARIO CONDITIONS #####\n",
    "# Population: 1 = baseline;\n",
    "population_scen = 1 # PQ\n",
    "\n",
    "# Cars per capita: 1 = baseline\n",
    "cars_per_capita_scen = 1 # CpCQ\n",
    "\n",
    "# Dismantling before ELVyear: 0 = none, 1 = low, 2 = high, 3 = all\n",
    "ELV_year = 1990 # ELVyear\n",
    "dismant_pre_ELV_scen = 0 # ELVQ1\n",
    "\n",
    "# Dismantling from ELVyear: 0 = none, 1 = low, 2 = high, 3 = all\n",
    "dismant_post_ELV_scen = 1 # ELVQ2\n",
    "\n",
    "# Alloy sorting scenario: 0 = none, 2 = laser sorting\n",
    "sorting_scen = 2 # ZQ\n",
    "\n",
    "# LIBS implmentation rate: 0 = none, 1 = low, 2 = medium, 3 = immediate, 100%\n",
    "LIBS_rate_scen = 1 #LIBSrate\n",
    "\n",
    "# Lifetime scenario: 2 = baseline, 1 = low, 3 = high\n",
    "lifetime_scen = 2 #LTQ\n",
    "\n",
    "# Demagging: 1 = on, 2 = off\n",
    "demag_scen = 1 #DMGQ\n",
    "\n",
    "# Zorba scenario: 0 = current, 1 = 2% reduction\n",
    "zorba_export_scen = 0 # Zorba_export\n",
    "\n",
    "##### PARAMETERS #####\n",
    "# Number of alloy groups that are sorted, e.g. 1xxx, 3xxx\n",
    "num_sorted_alloy_groups = 8 # NAG\n",
    "\n",
    "# This parameter reduces the amount of scrap that can be intelligently sorted as empirical data \n",
    "# has been collected that indicates that approximately 25% of scrap partiuculates are under 1 inch\n",
    "sizelimited = 0.25\n",
    "\n",
    "##### Variables #####\n",
    "\n",
    "# importing all sheets from excel sheet: 'LIBS Rate Input Data.xlsx'\n",
    "data = pd.read_excel('LIBS Rate Input Data.xlsx', sheet_name = None)\n",
    "old_scrap = data['Old Scrap']                                                                               # other_old_scrap\n",
    "old_scrap_comp = data['Old Alloy Compositions']                                                             # other_comp\n",
    "laser_sorting_alloy_groups = data['Laser Sorting Alloy Groups']                                             # alloy_names\n",
    "#####################################################################\n",
    "\n",
    "alloy_data = data['Alloy Data'].reset_index(drop = True)\n",
    "#alloy_data = pd.MultiIndex.from_arrays(data['Alloy Data'].values)\n",
    "\n",
    "#####################################################################\n",
    "auto_data = data['Auto Data']\n",
    "scenario_data = data['Scenarios']\n",
    "group_comp_by_alloy = data['Group Composition by Alloy']\n",
    "hand_sort = data['Hand Sorting']                                                                            # ZR_RaZ(:,:,1)       \n",
    "laser_sort = data['Laser Sorting']                                                                          # ZR_RaZ(:,:,2)\n",
    "primary_metal_comp = data['Primary Metal Composition']                                                      # CP_Ee\n",
    "element_yields = data['Element Yields']\n",
    "component_yields = data['Componenent Yields']\n",
    "opt_costs = data['Optimization Costs']\n",
    "\n",
    "# creating variables for names of headers\n",
    "alloy_names = list(old_scrap_comp.index)                                                                    # AlloyNames\n",
    "element_names = list(data['Old Alloy Compositions'].columns)                                                # ElementNames\n",
    "raw_material_names = list(data['Laser Sorting Alloy Groups'].index)                                         # RawMaterialNames\n",
    "comp_group_names = list(data['Auto Data'].columns)[3:]                                                      # GroupNames\n",
    "years = list(data['Auto Data']['Year'])                                                                     # Time\n",
    "\n",
    "# creating variables for number of columns for each feature\n",
    "num_raw_materials = len(raw_material_names)                                                                 # NR\n",
    "num_alloys = len(alloy_names)                                                                               # NA\n",
    "num_elements = len(element_names)                                                                           # NE\n",
    "num_component_groups = len(comp_group_names)                                                                # NG\n",
    "num_years = len(years)                                                                                      # NT\n",
    "num_segments = 1                                                                                            # NS\n",
    "num_cohorts = num_years # subject to change                                                                 # NC\n",
    "\n",
    "# creating misc variables\n",
    "# TODO: change values to be from the 'Scenarios' sheet of 'LIBS Rate Input Data'\n",
    "exp_life = 16                                                                                               # Mu\n",
    "std_dev = 3                                                                                                 # Sigma\n",
    "zorba_export_rate = [.45] * num_years\n",
    "collection_rate = [.98] * num_years\n",
    "shredder_yield = .95                                                                                        # SY\n",
    "secondary_alloys = True                                                                                     # SecondaryAlloysIndex\n",
    "primary_alloys = not secondary_alloys                                                                       # PrimaryAlloysIndex\n",
    "\n",
    "# importing data from within excel sheets\n",
    "population = auto_data['Population']                                                                        # P_T\n",
    "cars_per_capita = auto_data['CpC'] / 1000                                                                   # CpC_T\n",
    "segmentation = [1] * num_years # always 100% on spreadsheet (fraction of input)                             # SGM_Ts\n",
    "avg_Al_weight_per_comp = auto_data[list(auto_data.columns)[3:]]                                             # GW_TSG\n",
    "LIBS_rate = scenario_data['LIBS Rate' + str(LIBS_rate_scen)]                                                # LIBSrate\n",
    "ELV_rate_pre = data['ELV Scenario'].iloc[:, dismant_pre_ELV_scen]\n",
    "ELV_rate_post = data['ELV Scenario'].iloc[:, dismant_post_ELV_scen]\n",
    "ELV_year_index = scenario_data.Year[scenario_data.Year == ELV_year].index[0]\n",
    "ELV_by_comp = pd.DataFrame(np.concatenate((np.ones((ELV_year_index,1)).dot(ELV_rate_pre.to_frame().T),      # ELV_TG\n",
    "                                           np.ones((num_years - ELV_year_index,1)).\n",
    "                                           dot(ELV_rate_post.to_frame().T)), axis = 0),\n",
    "                           columns = list(auto_data.columns)[3:])                                                  \n",
    "sorting_rates = scenario_data[['Sorting' + str(sorting_scen) + ' Hand',                                     # Z_Tz\n",
    "                               'Sorting' + str(sorting_scen) + ' Laser']]     \n",
    "remelting_yields = element_yields.loc['Remelting Yields']                                                   # RY\n",
    "shredder_cont = element_yields.loc['Shredder Contamination']                                                # SC_e\n",
    "shredder_cont_dism = element_yields.loc['Shredder Contamination with Dismantled Parts']                     # SCD_e\n",
    "manufacture_yields = component_yields.loc['Manufacturing']                                                  # MY_G\n",
    "alloy_opt_costs = opt_costs.loc['Optimization Cost']                                                        # H_R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Variable Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# X01 - Kg\n",
    "X01_TR = np.zeros((num_years, num_raw_materials))\n",
    "\n",
    "# X07a - Kg\n",
    "X07a_TE = np.zeros((num_years, num_elements))\n",
    "\n",
    "# X07b - Kg\n",
    "X07b_TE = np.zeros((num_years, num_elements))\n",
    "\n",
    "# X10 - Kg\n",
    "X10_TR = np.zeros((num_years, num_raw_materials))\n",
    "\n",
    "# X12 - Kg\n",
    "X12_TAE = np.zeros((num_years, num_alloys, num_elements))\n",
    "X12_TRA = np.zeros((num_years, num_raw_materials, num_alloys))\n",
    "X12_TR = np.zeros((num_years, num_raw_materials))\n",
    "X12_RAE = np.zeros((num_raw_materials, num_alloys, num_elements))\n",
    "\n",
    "# X20 - Kg\n",
    "X20_TAE = np.zeros((num_years, num_alloys, num_elements))\n",
    "\n",
    "# X23 - Kg\n",
    "X23_TAE = np.zeros((num_years, num_alloys, num_elements))\n",
    "X23_conc_TAE = np.zeros((num_years, num_alloys, num_elements))\n",
    "X23_TA = np.zeros((num_years, num_alloys))\n",
    "X23_TG = np.zeros((num_years, num_component_groups))\n",
    "X23_TGA = np.zeros((num_years, num_component_groups, num_alloys))\n",
    "X23_TGE = np.zeros((num_years, num_component_groups, num_elements))                                             # X23_TGe\n",
    "\n",
    "# X31 - Kg\n",
    "X301_TG = np.zeros((num_years, num_component_groups))\n",
    "X31_TRE = np.zeros((num_years, num_raw_materials, num_elements))\n",
    "X31_TAR = np.zeros((num_years, num_alloys, num_raw_materials))\n",
    "X301_TGA = np.zeros((num_years, num_component_groups, num_alloys))\n",
    "\n",
    "# X34 - Kg\n",
    "X34_TG = np.zeros((num_years, num_component_groups))\n",
    "\n",
    "# X40 - Export\n",
    "X40_TG = np.zeros((num_years, num_component_groups))\n",
    "X40_T = np.zeros((num_years, 1))\n",
    "\n",
    "# X45 - Cars, Kg\n",
    "X45_TS = np.zeros((num_years, num_segments)) # Cars\n",
    "X45_TG = np.zeros((num_years, num_component_groups))\n",
    "X45_T = np.zeros((num_years, 1))\n",
    "\n",
    "# X50 - Kg\n",
    "X50_TCG = np.zeros((num_years, num_cohorts, num_component_groups))\n",
    "\n",
    "# X56 - Kg\n",
    "X56_TCG = np.zeros((num_years, num_cohorts, num_component_groups))\n",
    "\n",
    "# X560 - Cars, Kg\n",
    "X560_T = np.zeros((num_years, 1))\n",
    "X560_TC = np.zeros((num_years, num_cohorts)) # Cars\n",
    "X560_TCG = np.zeros((num_years, num_cohorts, num_component_groups))\n",
    "X560_TCA = np.zeros((num_years, num_cohorts, num_alloys))\n",
    "X560_TCE = np.zeros((num_years, num_cohorts, num_elements))\n",
    "X560_TE = np.zeros((num_years, num_elements))\n",
    "\n",
    "# X67a - Kg\n",
    "X67a_TCG = np.zeros((num_years, num_cohorts, num_component_groups))\n",
    "X67a_TCGA = np.zeros((num_years, num_cohorts, num_component_groups, num_alloys))\n",
    "X67a_TCGE = np.zeros((num_years, num_cohorts, num_component_groups, num_elements))\n",
    "X67a_TGE = np.zeros((num_years, num_component_groups, num_elements))\n",
    "X67b_TA = np.zeros((num_years, num_alloys))\n",
    "\n",
    "# X67b - Kg\n",
    "X67b_TCA = np.zeros((num_years, num_cohorts, num_alloys))\n",
    "X67b_TAE = np.zeros((num_years, num_alloys, num_elements))\n",
    "X67b_TCAE = np.zeros((num_years, num_component_groups, num_alloys, num_elements))\n",
    "X67b_TCGE = np.zeros((num_years, num_cohorts, num_component_groups, num_elements))\n",
    "X67b_TAE = np.zeros((num_years, num_alloys, num_elements))\n",
    "X67b_T = np.zeros((num_years, 1))                                                                               # X67a_otherT\n",
    "X67b_TA = np.zeros((num_years, num_alloys))                                                                     # X67a_otherTA\n",
    "X67b_TAE_other = np.zeros((num_years, num_alloys, num_elements))                                                # X67b_otherTAE\n",
    "\n",
    "# X7a1 - Kg\n",
    "X7a1_TRE = np.zeros((num_years, num_raw_materials, num_elements))\n",
    "X7a1_TGE = np.zeros((num_years, num_component_groups, num_elements))\n",
    "\n",
    "# X7b1 - Kg\n",
    "X7b1_TRE = np.zeros((num_years, num_raw_materials, num_elements))\n",
    "X7b1b_TRE = np.zeros((num_years, num_raw_materials, num_elements))\n",
    "X7b1_TRE_nocont = np.zeros((num_years, num_raw_materials, num_elements))\n",
    "X7b1s_TRE = np.zeros((num_years, num_raw_materials, num_elements))\n",
    "\n",
    "# X81 - Kg\n",
    "X81_TRE = np.zeros((num_years, num_raw_materials, num_elements))\n",
    "\n",
    "# S (Stock) - Cars, Kg\n",
    "S_TCG = np.zeros((num_years, num_cohorts, num_component_groups))                                                # M5_TCG\n",
    "S_TC = np.zeros((num_years, num_cohorts)) # Cars                                                                # M5_TC\n",
    "S_T = np.zeros((num_years, 1)) # Cars                                                                              # M5_T\n",
    "S_TCA = np.zeros((num_years, num_cohorts, num_alloys))                                                          # M5_TCA\n",
    "S_TE = np.zeros((num_years, num_elements))                                                                      # M5_TE\n",
    "S_TCE = np.zeros((num_years, num_cohorts, num_elements))                                                        #M5_TCE\n",
    "\n",
    "# APR (Alloy Production Recipe) - Kg\n",
    "APR_adj_TRA = np.zeros((num_years, num_raw_materials, num_alloys))                                              # Yadj_TRA\n",
    "APR_adj_RAE = np.zeros((num_raw_materials, num_alloys, num_elements))                                           # Yadj_RAE\n",
    "APR_RA = np.zeros((num_raw_materials, num_alloys))                                                              # Y_RA\n",
    "APR_RAE = np.zeros((num_raw_materials, num_alloys, num_elements))                                               # Y_RAE\n",
    "APR_TRA = np.zeros((num_years, num_raw_materials, num_alloys))                                                  # Y_TRA\n",
    "\n",
    "# SRM (Suppy of Raw Materials) - Kg\n",
    "SRM_TRE = np.zeros((num_years, num_raw_materials, num_elements))                                                # U_TRE\n",
    "SRM_TR = np.zeros((num_years, num_raw_materials))                                                               # U_TR\n",
    "SRM_conc_TRE = np.zeros((num_years, num_raw_materials, num_elements))                                           # U_TRe\n",
    "for y in range(num_years):\n",
    "    SRM_conc_TRE[y][:num_elements + 1] = primary_metal_comp\n",
    "    SRM_TRE[y][:num_elements + 1] = [[math.inf] * len(primary_metal_comp.columns)] * len(primary_metal_comp.index)\n",
    "    SRM_TR[y] = np.sum(SRM_TRE[y], axis = 1)\n",
    "    if (demag_scen == 2):\n",
    "        SRM_conc_TRE[y][num_elements] = [0] * num_elements\n",
    "        SRM_TR[y][num_elements] = 0\n",
    "\n",
    "# D (amount of magnesium removed)\n",
    "D_TRA = np.zeros((num_years, num_raw_materials, num_alloys))                                                    # demagg_TRA\n",
    "D_TA = np.zeros((num_years, num_alloys))                                                                        # demagg_TA\n",
    "D_T = np.zeros(num_years)                                                                                       # demagg_T\n",
    "D_TAE = np.zeros((num_years, num_alloys, num_elements))                                                         # demagg_TAE\n",
    "\n",
    "# shred_contam (shredder contamination)\n",
    "shred_contam = np.zeros(num_years)                                                                              # shredder_contamination\n",
    "\n",
    "##### Composition of Alloys #####\n",
    "# AC (alloy compositon)\n",
    "AC_upper_AE = np.zeros((num_alloys, num_elements))                                                              # CAU_Ae\n",
    "AC_lower_AE = np.zeros((num_alloys, num_elements))                                                              # CAL_Ae\n",
    "for i_a, a in enumerate(alloy_names):\n",
    "    a_df = alloy_data[alloy_data['Alloy'] == a] # equivalent to open_alloy(alloy_name, structure)\n",
    "    for i_e, e in enumerate(element_names[1:]):\n",
    "        if float(a_df[a_df['Level'] == 'Nominal'][e]) == 0:\n",
    "            AC_upper_AE[i_a][i_e] = float(a_df[a_df['Level'] == 'Maximum'][e]) / 100\n",
    "            AC_lower_AE[i_a][i_e] = 0\n",
    "        else:\n",
    "            AC_upper_AE[i_a][i_e] = float(a_df[a_df['Level'] == 'Nominal'][e]) / 100\n",
    "            AC_lower_AE[i_a][i_e] = float(a_df[a_df['Level'] == 'Nominal'][e]) / 100\n",
    "    AC_upper_AE[i_a][0] = 1 - sum(AC_lower_AE[i_a][1:])\n",
    "    AC_lower_AE[i_a][0] = 1 - sum(AC_upper_AE[i_a][1:])\n",
    "# set Al minimum content in 1070A to be .997 for some reason?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skeleton Stock-Driven Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalDistTrunc(mu, sigma, time): # normal_distribution_trunc0\n",
    "    dist = np.zeros((time, 1))\n",
    "    for y in range(time):\n",
    "        dist[y] = norm.cdf(y + 1, mu, sigma) - norm.cdf(y, mu, sigma)\n",
    "    dist /= (1 - norm.cdf(0, mu, sigma))\n",
    "    return dist\n",
    "\n",
    "def stockDrivenModel(stock, dist):\n",
    "    time = len(stock)\n",
    "    stock_change = np.zeros((time, 1))\n",
    "    stock_change[0] = stock[0]\n",
    "    inp = np.zeros((time,1))\n",
    "    inp[0] = stock[0]\n",
    "    out = np.zeros((time, 1))\n",
    "    out_cohort = np.zeros((time, time))\n",
    "    stock_cohort = np.zeros((time, time))\n",
    "    stock_cohort[0][0] = inp[0]\n",
    "    \n",
    "    for ot in range(1, time): # output time\n",
    "        stock_change[ot] = stock[ot] - stock[ot - 1]\n",
    "        for it in range(ot - 1): # input time\n",
    "            out_cohort[ot][it] = inp[it] * dist[ot - it]\n",
    "        out[ot] = np.sum(out_cohort[ot])\n",
    "        inp[ot] = stock_change[ot] + out[ot]\n",
    "        for ct in range(ot): # current time\n",
    "            stock_cohort[ot][ct] = inp[ct] - np.sum(out_cohort[:ot][ct])\n",
    "    return inp, out, out_cohort, stock_cohort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Stock Calculation\n",
    "S_T = np.multiply(cars_per_capita, population)\n",
    "\n",
    "prob_dist = normalDistTrunc(exp_life, std_dev, num_years)\n",
    "input_T, output_T, X560_TC, S_TC = stockDrivenModel(S_T, prob_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00000000e+00]\n",
      " [0.00000000e+00]\n",
      " [5.89189098e-02]\n",
      " [2.48333665e-01]\n",
      " [9.33348969e-01]\n",
      " [3.13966148e+00]\n",
      " [9.46042621e+00]\n",
      " [2.68009954e+01]\n",
      " [6.85564735e+01]\n",
      " [1.61721864e+02]\n",
      " [3.59400642e+02]\n",
      " [7.69612439e+02]\n",
      " [1.61706470e+03]\n",
      " [3.35397053e+03]\n",
      " [6.81061038e+03]\n",
      " [1.33190271e+04]\n",
      " [2.46818041e+04]\n",
      " [4.28603790e+04]\n",
      " [6.93824255e+04]\n",
      " [1.04680386e+05]\n",
      " [1.47719338e+05]\n",
      " [1.96189619e+05]\n",
      " [2.47231109e+05]\n",
      " [2.98335578e+05]\n",
      " [3.47990201e+05]\n",
      " [3.95831364e+05]\n",
      " [4.42387786e+05]\n",
      " [4.88671808e+05]\n",
      " [5.35847076e+05]\n",
      " [5.85053451e+05]\n",
      " [6.37343970e+05]\n",
      " [6.93650000e+05]\n",
      " [7.54721148e+05]\n",
      " [8.21036893e+05]\n",
      " [8.92722238e+05]\n",
      " [9.69508973e+05]\n",
      " [1.05077109e+06]\n",
      " [1.13563728e+06]\n",
      " [1.22315669e+06]\n",
      " [1.31247677e+06]\n",
      " [1.40298995e+06]\n",
      " [1.49441863e+06]\n",
      " [1.58682851e+06]\n",
      " [1.68057971e+06]\n",
      " [1.77623745e+06]\n",
      " [1.87446603e+06]\n",
      " [1.97592587e+06]\n",
      " [2.08118624e+06]\n",
      " [2.19066052e+06]\n",
      " [2.30456783e+06]\n",
      " [2.42292238e+06]\n",
      " [2.54555087e+06]\n",
      " [2.67213495e+06]\n",
      " [2.80227263e+06]\n",
      " [2.93554888e+06]\n",
      " [3.07160390e+06]\n",
      " [3.21018806e+06]\n",
      " [3.35119515e+06]\n",
      " [3.49467004e+06]\n",
      " [3.64079175e+06]\n",
      " [3.78983704e+06]\n",
      " [3.94213211e+06]\n",
      " [4.09800130e+06]\n",
      " [4.25772053e+06]\n",
      " [4.42148202e+06]\n",
      " [4.58937405e+06]\n",
      " [4.76137725e+06]\n",
      " [4.93737640e+06]\n",
      " [5.11718466e+06]\n",
      " [5.30057573e+06]\n",
      " [5.48731861e+06]\n",
      " [5.67720948e+06]\n",
      " [5.87009642e+06]\n",
      " [6.06589344e+06]\n",
      " [6.26458293e+06]\n",
      " [6.46620680e+06]\n",
      " [6.67084874e+06]\n",
      " [6.87861102e+06]\n",
      " [7.08958977e+06]\n",
      " [7.30385259e+06]\n",
      " [7.52142166e+06]\n",
      " [7.74226436e+06]\n",
      " [7.96629205e+06]\n",
      " [8.19336663e+06]\n",
      " [8.42331310e+06]\n",
      " [8.65593574e+06]\n",
      " [8.89103526e+06]\n",
      " [9.12842436e+06]\n",
      " [9.36793931e+06]\n",
      " [9.60944642e+06]\n",
      " [9.85284279e+06]\n",
      " [1.00980516e+07]\n",
      " [1.03450136e+07]\n",
      " [1.05936753e+07]\n",
      " [1.08439779e+07]\n",
      " [1.10958461e+07]\n",
      " [1.13491808e+07]\n",
      " [1.16038545e+07]\n",
      " [1.18597118e+07]\n",
      " [1.21165728e+07]\n",
      " [1.23742396e+07]\n",
      " [1.26325045e+07]\n",
      " [1.28911589e+07]\n",
      " [1.31500003e+07]\n",
      " [1.34088387e+07]\n",
      " [1.36674991e+07]\n",
      " [1.39258220e+07]\n",
      " [1.41836612e+07]\n",
      " [1.44408797e+07]\n",
      " [1.46973440e+07]\n",
      " [1.49529187e+07]\n",
      " [1.52074617e+07]\n",
      " [1.54608208e+07]\n",
      " [1.57128318e+07]\n",
      " [1.59633189e+07]\n",
      " [1.62120967e+07]\n",
      " [1.64589725e+07]\n",
      " [1.67037494e+07]\n",
      " [1.69462274e+07]\n",
      " [1.71862031e+07]\n",
      " [1.74234659e+07]\n",
      " [1.76577920e+07]\n",
      " [1.78889377e+07]\n",
      " [1.81166334e+07]\n",
      " [1.83405804e+07]\n",
      " [1.85604508e+07]\n",
      " [1.87758897e+07]\n",
      " [1.89865189e+07]\n",
      " [1.91919408e+07]\n",
      " [1.93917410e+07]\n",
      " [1.95854906e+07]\n",
      " [1.97727479e+07]\n",
      " [1.99530590e+07]\n",
      " [2.01259578e+07]\n",
      " [2.02909660e+07]\n",
      " [2.04475912e+07]\n",
      " [2.05953255e+07]\n",
      " [2.07336432e+07]\n",
      " [2.08619990e+07]\n",
      " [2.09798263e+07]\n",
      " [2.10865364e+07]\n",
      " [2.11815193e+07]\n",
      " [2.12641440e+07]\n",
      " [2.13337605e+07]\n",
      " [2.13897022e+07]\n",
      " [2.14312873e+07]\n",
      " [2.14578213e+07]\n",
      " [2.14685983e+07]\n",
      " [2.14629021e+07]\n",
      " [2.14400065e+07]\n",
      " [2.13991759e+07]]\n"
     ]
    }
   ],
   "source": [
    "print(output_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05891891 0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]\n"
     ]
    }
   ],
   "source": [
    "print(X560_TC[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
